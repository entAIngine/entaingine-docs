<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-getting-started/understanding-rag" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">Understanding Retrieval-Augmented Generation (RAG) | entAIngine documentation</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://docs.entaingine.com/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://docs.entaingine.com/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://docs.entaingine.com/getting-started/understanding-rag"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Understanding Retrieval-Augmented Generation (RAG) | entAIngine documentation"><meta data-rh="true" name="description" content="Large language models (LLMs) can do a lot and enable many applications, but there are scenarios where LLMs fall short. This often happens when you need to leverage private knowledge, update information periodically, or work with very large knowledge bases. This is why we use retrieval-augmented generation (RAG) — a powerful approach for integrating dynamic and private information with generative AI."><meta data-rh="true" property="og:description" content="Large language models (LLMs) can do a lot and enable many applications, but there are scenarios where LLMs fall short. This often happens when you need to leverage private knowledge, update information periodically, or work with very large knowledge bases. This is why we use retrieval-augmented generation (RAG) — a powerful approach for integrating dynamic and private information with generative AI."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://docs.entaingine.com/getting-started/understanding-rag"><link data-rh="true" rel="alternate" href="https://docs.entaingine.com/getting-started/understanding-rag" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.entaingine.com/getting-started/understanding-rag" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.df2753d3.css">
<script src="/assets/js/runtime~main.c30e036b.js" defer="defer"></script>
<script src="/assets/js/main.7eac0c35.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="entAIngine Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="entAIngine Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">entAIngine wiki</b></a></div><div class="navbar__items navbar__items--right"><a href="https://jadenx.atlassian.net/servicedesk/customer/portals" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Help Desk<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://entaingine.statuspage.io/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Health Status<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/category/introduction">Introduction</a><button aria-label="Expand sidebar category &#x27;Introduction&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/category/getting-started">Getting Started</a><button aria-label="Collapse sidebar category &#x27;Getting Started&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/introduction">Introduction to entAIngine Onboarding</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/quick-start-guide">Getting Started with entAIngine</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/process-mindset">Developing a Process Mindset</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/overview">Building Your First Process with entAIngine</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/invoice-controlling-example">Invoice Controlling Example</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/application-setup">Application Setup in entAIngine</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/orchestration-and-testing">Orchestrating, Testing, Scaling, and Automating the Process</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/scaling-and-automation">Scaling and Customizing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/getting-started/understanding-rag">Understanding Retrieval-Augmented Generation (RAG)</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/category/user-guides">User Guides</a><button aria-label="Expand sidebar category &#x27;User Guides&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/category/developer-guide">Developer Guide</a><button aria-label="Expand sidebar category &#x27;Developer Guide&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/category/getting-started"><span itemprop="name">Getting Started</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Understanding Retrieval-Augmented Generation (RAG)</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Understanding Retrieval-Augmented Generation (RAG)</h1>
<p>Large language models (LLMs) can do a lot and enable many applications, but there are scenarios where LLMs fall short. This often happens when you need to leverage private knowledge, update information periodically, or work with very large knowledge bases. This is why we use retrieval-augmented generation (RAG) — a powerful approach for integrating dynamic and private information with generative AI.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-do-we-need-retrieval-augmented-generation">Why Do We Need Retrieval-Augmented Generation?<a href="#why-do-we-need-retrieval-augmented-generation" class="hash-link" aria-label="Direct link to Why Do We Need Retrieval-Augmented Generation?" title="Direct link to Why Do We Need Retrieval-Augmented Generation?">​</a></h2>
<p>To understand the necessity of RAG, consider this: if you ask an LLM about your company&#x27;s revenue in the EMEA region for the previous year, it will likely respond that it doesn&#x27;t have access to your financial data. Alternatively, it might generate an inaccurate response by guessing. This limitation exists because LLMs rely on pre-trained data, and there is no direct way for them to access proprietary, private, or frequently changing information.</p>
<p>LLMs like GPT-4 are trained on a vast dataset of publicly available content, including forums, blogs, and books. They are statistical models that predict text based on patterns and probabilities derived from this training data, rather than accessing specific sources of information. This means that the knowledge they provide is representative of general public knowledge — often accurate, but not always verifiable or complete.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="challenges-of-llm-only-solutions">Challenges of LLM-Only Solutions<a href="#challenges-of-llm-only-solutions" class="hash-link" aria-label="Direct link to Challenges of LLM-Only Solutions" title="Direct link to Challenges of LLM-Only Solutions">​</a></h2>
<p>When using only LLMs without supporting structures, several challenges arise:</p>
<ul>
<li><strong>Static Knowledge</strong>: LLMs are frozen in time. The knowledge they hold is limited to what was available during the training period. Updating an LLM requires costly retraining or fine-tuning, and outdated information can be difficult to remove.</li>
<li><strong>Lack of Domain-Specific Knowledge</strong>: General-purpose LLMs are not trained on your company&#x27;s proprietary data, such as revenue statements or project reports. This limits their ability to provide context-specific answers.</li>
<li><strong>Opaque Decision-Making</strong>: LLMs function as black boxes, making it impossible to trace back the exact sources behind a generated answer. This is problematic for enterprises that require verifiability and accountability.</li>
<li><strong>Costly and Complex to Train</strong>: Building and fine-tuning LLMs is expensive and requires significant technical expertise. Fine-tuning adds more knowledge to the model but doesn&#x27;t solve the inherent issues of opacity and outdated information.</li>
<li><strong>Context Size Limitations</strong>: LLMs have limits on the amount of context they can handle in a single prompt. For example, GPT-4o can take up to 128,000 tokens — enough for a 100-page book, but insufficient for larger knowledge bases.</li>
</ul>
<p>These challenges make LLMs unsuitable for scenarios where up-to-date, verifiable, and extensive information is required, especially for enterprise applications.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-retrieval-augmented-generation">What Is Retrieval-Augmented Generation?<a href="#what-is-retrieval-augmented-generation" class="hash-link" aria-label="Direct link to What Is Retrieval-Augmented Generation?" title="Direct link to What Is Retrieval-Augmented Generation?">​</a></h2>
<p>RAG augments the capabilities of LLMs by incorporating data retrieval mechanisms. It works in two phases:</p>
<ol>
<li><strong>Building a Knowledge Base</strong>: The first phase involves building a vector database with your organization&#x27;s knowledge. This includes raw documents, chunks of information, and their corresponding vector representations.</li>
<li><strong>Querying the Knowledge Base</strong>: In the second phase, when a user queries the system, a semantic search is performed on the vector database. The search results are then used to generate an enriched and context-specific response using an LLM.</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="building-a-rag-pipeline">Building a RAG Pipeline<a href="#building-a-rag-pipeline" class="hash-link" aria-label="Direct link to Building a RAG Pipeline" title="Direct link to Building a RAG Pipeline">​</a></h2>
<p>The first step in creating a RAG pipeline is <strong>chunking</strong> — dividing large documents into smaller, meaningful sections called chunks. These chunks are then translated into vectors using an embedding model, which provides a numeric representation of the semantics of each chunk.</p>
<p>The vectors are stored in a vector database, which allows for efficient semantic searches. When a query is made, the system searches through these vectors to find the chunks that are semantically closest to the query. This enables us to provide highly relevant information without relying solely on the LLM&#x27;s pre-trained knowledge.</p>
<img src="/img/getting-started/how-rag-works.png" alt="how rag works">
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="embedding-and-vector-representation">Embedding and Vector Representation<a href="#embedding-and-vector-representation" class="hash-link" aria-label="Direct link to Embedding and Vector Representation" title="Direct link to Embedding and Vector Representation">​</a></h3>
<p>An embedding model translates each chunk into a vector, capturing the semantic meaning of the text. These vectors are then stored in a vector database. For example, similar sentences like &quot;a little boy is walking&quot; and &quot;a little boy is running&quot; will have similar vector representations, allowing the system to recognize their semantic closeness.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="querying-and-generating-responses">Querying and Generating Responses<a href="#querying-and-generating-responses" class="hash-link" aria-label="Direct link to Querying and Generating Responses" title="Direct link to Querying and Generating Responses">​</a></h3>
<p>When a user makes a query, an embedding of that query is generated and compared to the stored vectors. The closest matching chunks are retrieved, and these chunks are then used to generate a response.</p>
<p>To further enhance quality, an optional step called <strong>retrieval reranking</strong> can be added. In this step, the top K results are fed into an LLM for re-ranking, ensuring the final output is both relevant and accurate.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="advantages-of-rag-over-llm-only-approaches">Advantages of RAG Over LLM-Only Approaches<a href="#advantages-of-rag-over-llm-only-approaches" class="hash-link" aria-label="Direct link to Advantages of RAG Over LLM-Only Approaches" title="Direct link to Advantages of RAG Over LLM-Only Approaches">​</a></h2>
<ul>
<li><strong>Dynamic Knowledge</strong>: Unlike LLMs, RAG pipelines are not static. You can easily add, update, or delete information in the vector database, ensuring your knowledge base remains up to date.</li>
<li><strong>Domain-Specific Knowledge</strong>: With RAG, you can insert proprietary and domain-specific knowledge, giving your organization control over the data used in generating responses.</li>
<li><strong>Traceability</strong>: RAG enables traceability by allowing you to link the generated output back to its original source. This is particularly useful for enterprises that require verifiable information.</li>
<li><strong>Cost Efficiency</strong>: Embedding models and vector searches are much less costly compared to running large LLMs for every query. This makes RAG a cost-effective solution for handling large amounts of data.</li>
<li><strong>Handling Large Knowledge Bases</strong>: RAG allows you to efficiently work with large knowledge bases, avoiding the context size limitations inherent to LLMs.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary">​</a></h2>
<p>Retrieval-Augmented Generation combines the strengths of LLMs with the flexibility and efficiency of data retrieval. By using RAG, you can overcome the limitations of LLM-only approaches, such as static knowledge, lack of domain-specific information, and high costs. RAG pipelines allow you to leverage private knowledge, ensure verifiability, and create dynamic, enterprise-grade AI solutions.</p>
<p>For enterprises looking to harness the power of generative AI in a secure, scalable, and cost-efficient way, RAG provides a compelling solution.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="next-steps">Next Steps<a href="#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps">​</a></h2>
<p>To get started with building your own RAG pipeline, explore our detailed guides on setting up vector databases, choosing the right embedding models, and integrating retrieval mechanisms into your existing workflows. RAG can transform how your organization leverages AI, enabling more accurate, efficient, and traceable insights.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/entAIngine/entaingine-docs/tree/main/docs/getting-started/understanding-rag.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/getting-started/scaling-and-automation"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Scaling and Customizing</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/category/conceptual-onboarding"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Conceptual Onboarding</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#why-do-we-need-retrieval-augmented-generation" class="table-of-contents__link toc-highlight">Why Do We Need Retrieval-Augmented Generation?</a></li><li><a href="#challenges-of-llm-only-solutions" class="table-of-contents__link toc-highlight">Challenges of LLM-Only Solutions</a></li><li><a href="#what-is-retrieval-augmented-generation" class="table-of-contents__link toc-highlight">What Is Retrieval-Augmented Generation?</a></li><li><a href="#building-a-rag-pipeline" class="table-of-contents__link toc-highlight">Building a RAG Pipeline</a><ul><li><a href="#embedding-and-vector-representation" class="table-of-contents__link toc-highlight">Embedding and Vector Representation</a></li><li><a href="#querying-and-generating-responses" class="table-of-contents__link toc-highlight">Querying and Generating Responses</a></li></ul></li><li><a href="#advantages-of-rag-over-llm-only-approaches" class="table-of-contents__link toc-highlight">Advantages of RAG Over LLM-Only Approaches</a></li><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a></li><li><a href="#next-steps" class="table-of-contents__link toc-highlight">Next Steps</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.youtube.com/@entAIngine-xs2db" target="_blank" rel="noopener noreferrer" class="footer__link-item">YouTube<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discord.gg/HSApqmUG" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.linkedin.com/company/entaingine/" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/entaingine" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 entAIngine</div></div></div></footer></div>
</body>
</html>