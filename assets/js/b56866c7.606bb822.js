"use strict";(self.webpackChunkentaingine_docs=self.webpackChunkentaingine_docs||[]).push([[3596],{9244:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>a,metadata:()=>r,toc:()=>h});var t=s(4848),i=s(8453);const a={title:"Chain-of-Thought Prompting",slug:"/prompting-techniques/chain-of-thought",sidebar_position:4,description:"Guide language models to reason step by step for complex tasks."},o=void 0,r={id:"prompting-techniques/chain-of-thought",title:"Chain-of-Thought Prompting",description:"Guide language models to reason step by step for complex tasks.",source:"@site/docs/prompting-techniques/chain-of-thought.mdx",sourceDirName:"prompting-techniques",slug:"/prompting-techniques/chain-of-thought",permalink:"/prompting-techniques/chain-of-thought",draft:!1,unlisted:!1,editUrl:"https://github.com/entAIngine/entaingine-docs/tree/main/docs/prompting-techniques/chain-of-thought.mdx",tags:[],version:"current",sidebarPosition:4,frontMatter:{title:"Chain-of-Thought Prompting",slug:"/prompting-techniques/chain-of-thought",sidebar_position:4,description:"Guide language models to reason step by step for complex tasks."},sidebar:"tutorialSidebar",previous:{title:"Few-Shot Prompting",permalink:"/prompting-techniques/few-shot"},next:{title:"Self-Consistency",permalink:"/prompting-techniques/self-consistency"}},l={},h=[{value:"\ud83c\udfaf Use When",id:"-use-when",level:2},{value:"\ud83d\udd04 Pattern",id:"-pattern",level:2},{value:"Examples",id:"examples",level:2},{value:"Example 1: Few-Shot CoT (Math Reasoning)",id:"example-1-few-shot-cot-math-reasoning",level:3},{value:"Example 2: Zero-Shot CoT",id:"example-2-zero-shot-cot",level:3},{value:"Example 3: Applied Physics (new)",id:"example-3-applied-physics-new",level:3},{value:"Variants",id:"variants",level:2},{value:"Benefits",id:"benefits",level:2},{value:"\u26a0\ufe0f Pitfalls",id:"\ufe0f-pitfalls",level:2},{value:"Visual Comparison",id:"visual-comparison",level:2},{value:"Automatic Chain-of-Thought",id:"automatic-chain-of-thought",level:2},{value:"References",id:"references",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:'Chain-of-Thought (CoT) Prompting is a technique that encourages language models to break down complex problems into a sequence of intermediate reasoning steps, rather than jumping directly to an answer. This approach enables models to "think out loud," improving accuracy, transparency, and robustness\u2014especially for tasks requiring logical or multi-step reasoning.'}),"\n",(0,t.jsxs)(n.p,{children:["Introduced by ",(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/2201.11903",children:"Wei et al. (2022)"}),", CoT has become a foundational method for eliciting reasoning in large language models (LLMs) and is widely used in research and industry."]}),"\n",(0,t.jsx)(n.h2,{id:"-use-when",children:"\ud83c\udfaf Use When"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"The task requires logical, mathematical, or multi-step reasoning"}),"\n",(0,t.jsx)(n.li,{children:"You want the model to explain its process, not just give an answer"}),"\n",(0,t.jsx)(n.li,{children:"Problems are complex, ambiguous, or benefit from stepwise decomposition"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"-pattern",children:"\ud83d\udd04 Pattern"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Few-Shot CoT:"})," Provide several examples of questions and detailed, step-by-step solutions. Then, present a new question for the model to solve in the same way"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Zero-Shot CoT:"}),' Add a phrase like "Let\'s think step by step" to the prompt, encouraging the model to generate a reasoning chain even without examples']}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"examples",children:"Examples"}),"\n",(0,t.jsx)(n.h3,{id:"example-1-few-shot-cot-math-reasoning",children:"Example 1: Few-Shot CoT (Math Reasoning)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"Q: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\nA: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n\nQ: The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\nA: Adding all the odd numbers (15, 5, 13, 7, 1) gives 41. The answer is False.\n\nQ: The odd numbers in this group add up to an even number: 17, 10, 19, 4, 8, 12, 24.\nA: Adding all the odd numbers (17, 19) gives 36. The answer is True.\n\nQ: The odd numbers in this group add up to an even number: 16, 11, 14, 4, 8, 13, 24.\nA: Adding all the odd numbers (11, 13) gives 24. The answer is True.\n\nQ: The odd numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.\nA:\n"})}),"\n",(0,t.jsx)(n.h3,{id:"example-2-zero-shot-cot",children:"Example 2: Zero-Shot CoT"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then bought 5 more apples and ate 1. How many apples did I remain with?\n\nLet's think step by step.\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Model output:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"First, you started with 10 apples.\nYou gave away 2 apples to the neighbor and 2 to the repairman, so you had 6 apples left.\nThen you bought 5 more apples, so now you had 11 apples.\nFinally, you ate 1 apple, so you would remain with 10 apples.\n"})}),"\n",(0,t.jsx)(n.h3,{id:"example-3-applied-physics-new",children:"Example 3: Applied Physics (new)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"A 12 kg object is in free fall for 4 seconds. What is the force exerted, given gravity is 9.8 m/s\xb2?\n\nLet's think step by step.\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Model output:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"The force exerted by an object in free fall is F = m \xd7 a.\nHere, m = 12 kg, a = 9.8 m/s\xb2.\nF = 12 \xd7 9.8 = 117.6 N.\nThe force is 117.6 Newtons.\n"})}),"\n",(0,t.jsx)(n.h2,{id:"variants",children:"Variants"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Zero-Shot CoT:"})," Add \u201cLet\u2019s think step by step\u201d to the prompt for reasoning without examples (",(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/2205.11916",children:"Kojima et al., 2022"}),")."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Automatic CoT:"})," Use LLMs to generate diverse reasoning chains for demonstrations (",(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/2210.02406",children:"Zhang et al., 2022"}),")."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Tabular CoT:"})," Structure reasoning in a table for clarity in data analysis tasks."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"benefits",children:"Benefits"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Improved accuracy:"})," Stepwise reasoning reduces errors in complex tasks."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Explainability:"})," Makes the model\u2019s logic transparent and auditable."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Robustness:"})," Helps identify and correct mistakes in intermediate steps."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"\ufe0f-pitfalls",children:"\u26a0\ufe0f Pitfalls"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"May generate unnecessary details for simple tasks"}),"\n",(0,t.jsx)(n.li,{children:"Can increase response length and cost"}),"\n",(0,t.jsx)(n.li,{children:"Effectiveness depends on the quality and diversity of provided examples (for few-shot)"}),"\n"]}),"\n",(0,t.jsx)(n.admonition,{title:"Pro Tip",type:"tip",children:(0,t.jsx)(n.p,{children:"Start with simple examples and gradually increase complexity. Quality examples are more important than quantity!"})}),"\n",(0,t.jsx)(n.h2,{id:"visual-comparison",children:"Visual Comparison"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Chain-of-Thought Prompting Illustration",src:s(6900).A+"",width:"940",height:"473"})}),"\n",(0,t.jsx)(n.p,{children:"The diagram above illustrates the key difference between standard prompting and Chain-of-Thought prompting. CoT prompting enables intermediate reasoning steps that make the process transparent and more reliable, as demonstrated in this example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'Standard Prompting:\nQuestion: "What is 15 + 27 \xd7 3?"\nModel: "96"\n\nChain-of-Thought Prompting:\nQuestion: "What is 15 + 27 \xd7 3?"\nModel: "I need to follow order of operations.\n        First: 27 \xd7 3 = 81\n        Then: 15 + 81 = 96\n        Therefore: 96"\n'})}),"\n",(0,t.jsx)(n.h2,{id:"automatic-chain-of-thought",children:"Automatic Chain-of-Thought"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Auto-CoT Framework",src:s(3880).A+"",width:"1113",height:"606"})}),"\n",(0,t.jsx)(n.p,{children:"Automatic Chain-of-Thought (Auto-CoT) extends the basic CoT approach by automatically generating reasoning demonstrations. Instead of requiring manual creation of exemplars, Auto-CoT uses the model itself to generate diverse reasoning chains, reducing human effort while maintaining or improving performance."}),"\n",(0,t.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., ... & Zhou, D. (2022). ",(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/2201.11903",children:"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"}),". ",(0,t.jsx)(n.em,{children:"NeurIPS 2022"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Ishihata, M. (2022). ",(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/2205.11916",children:"Large Language Models are Zero-Shot Reasoners"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Zhang, Z., Zhang, A., Li, M., & Smola, A. (2022). ",(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/2210.02406",children:"Automatic Chain of Thought Prompting in Large Language Models"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., ... & Steinhardt, J. (2021). ",(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/2009.03300",children:"Measuring Massive Multitask Language Understanding"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Ahn, M., et al. (2022). ",(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/2201.07207",children:"Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Wei, J., et al. (2022). ",(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/2206.07682",children:"Emergent Abilities of Large Language Models"}),"."]}),"\n"]})]})}function c(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},3880:(e,n,s)=>{s.d(n,{A:()=>t});const t=s.p+"assets/images/auto-cot-f99d182f0161d99b1caf63ba0d8d2ddd.png"},6900:(e,n,s)=>{s.d(n,{A:()=>t});const t=s.p+"assets/images/cot-959bf0811774ebe45f045ce6ca027d33.png"},8453:(e,n,s)=>{s.d(n,{R:()=>o,x:()=>r});var t=s(6540);const i={},a=t.createContext(i);function o(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);