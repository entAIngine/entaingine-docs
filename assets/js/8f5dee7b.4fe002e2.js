"use strict";(self.webpackChunkentaingine_docs=self.webpackChunkentaingine_docs||[]).push([[7791],{3413:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>r,metadata:()=>o,toc:()=>c});var i=t(4848),s=t(8453);const r={title:"Automatic Prompt Engineer (APE)",slug:"/prompting-techniques/automatic-prompt-engineer",sidebar_position:11,description:"Use models to generate and refine prompts automatically for optimal performance."},a=void 0,o={id:"prompting-techniques/automatic-prompt-engineer",title:"Automatic Prompt Engineer (APE)",description:"Use models to generate and refine prompts automatically for optimal performance.",source:"@site/docs/prompting-techniques/automatic-prompt-engineer.mdx",sourceDirName:"prompting-techniques",slug:"/prompting-techniques/automatic-prompt-engineer",permalink:"/prompting-techniques/automatic-prompt-engineer",draft:!1,unlisted:!1,editUrl:"https://github.com/entAIngine/entaingine-docs/tree/main/docs/prompting-techniques/automatic-prompt-engineer.mdx",tags:[],version:"current",sidebarPosition:11,frontMatter:{title:"Automatic Prompt Engineer (APE)",slug:"/prompting-techniques/automatic-prompt-engineer",sidebar_position:11,description:"Use models to generate and refine prompts automatically for optimal performance."},sidebar:"tutorialSidebar",previous:{title:"ART (Automatic Reasoning and Tool-use)",permalink:"/prompting-techniques/art"},next:{title:"Active Prompt",permalink:"/prompting-techniques/active-prompt"}},l={},c=[{value:"How APE Works",id:"how-ape-works",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"Implementation Patterns",id:"implementation-patterns",level:2},{value:"Basic APE Pattern",id:"basic-ape-pattern",level:3},{value:"Iterative Refinement",id:"iterative-refinement",level:3},{value:"Meta-Prompt for APE",id:"meta-prompt-for-ape",level:3},{value:"Advanced Techniques",id:"advanced-techniques",level:2},{value:"Chain-of-Thought APE",id:"chain-of-thought-ape",level:3},{value:"Multi-Objective APE",id:"multi-objective-ape",level:3},{value:"Evaluation and Testing",id:"evaluation-and-testing",level:2},{value:"Quantitative Metrics",id:"quantitative-metrics",level:3},{value:"Qualitative Assessment",id:"qualitative-assessment",level:3},{value:"Implementation Example",id:"implementation-example",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"For Prompt Generation",id:"for-prompt-generation",level:3},{value:"For Evaluation",id:"for-evaluation",level:3},{value:"For Iteration",id:"for-iteration",level:3},{value:"Limitations and Considerations",id:"limitations-and-considerations",level:2},{value:"Integration with Other Techniques",id:"integration-with-other-techniques",level:2},{value:"References",id:"references",level:2}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"APE Framework Overview",src:t(9782).A+"",width:"783",height:"527"})}),"\n",(0,i.jsx)(n.p,{children:"Automatic Prompt Engineer (APE) is a technique that leverages language models themselves to automatically generate, test, and refine prompts for specific tasks. Instead of manually crafting prompts through trial and error, APE uses systematic approaches to discover high-performing prompt formulations, often surpassing human-designed prompts."}),"\n",(0,i.jsxs)(n.p,{children:["Introduced by ",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2211.01910",children:"Zhou et al. (2022)"}),", APE treats prompt generation as a natural language synthesis problem, where the model is asked to generate instructions that would lead to desired outputs given specific inputs."]}),"\n",(0,i.jsx)(n.h2,{id:"how-ape-works",children:"How APE Works"}),"\n",(0,i.jsx)(n.p,{children:"The APE process typically involves several key steps:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Prompt Generation"}),": The model generates multiple candidate prompts based on input-output examples"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Evaluation"}),": Each candidate prompt is tested on a validation set"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Selection"}),": The best-performing prompts are identified based on accuracy or other metrics"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Iteration"}),": The process can be repeated to further refine prompts"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,i.jsx)(n.p,{children:"APE is particularly valuable when:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Manual prompt engineering is time-consuming or requires domain expertise"}),"\n",(0,i.jsx)(n.li,{children:"You need to optimize prompts for specific metrics (accuracy, consistency, style)"}),"\n",(0,i.jsx)(n.li,{children:"Working with new tasks where effective prompt patterns aren't well-established"}),"\n",(0,i.jsx)(n.li,{children:"Scaling prompt optimization across multiple similar tasks"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"implementation-patterns",children:"Implementation Patterns"}),"\n",(0,i.jsx)(n.h3,{id:"basic-ape-pattern",children:"Basic APE Pattern"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:'Task: Generate a prompt that will help classify customer reviews as positive or negative.\n\nGiven these examples:\nInput: "This product exceeded my expectations!"\nOutput: Positive\n\nInput: "Waste of money, poor quality"\nOutput: Negative\n\nGenerate 5 different prompts that would work well for this classification task.\n'})}),"\n",(0,i.jsx)(n.h3,{id:"iterative-refinement",children:"Iterative Refinement"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:'Here are 3 prompts for sentiment analysis:\n1. "Classify this review as positive or negative:"\n2. "Determine the sentiment (positive/negative) of this customer feedback:"\n3. "Is this review expressing a positive or negative opinion?"\n\nBased on testing, prompt #2 performed best. Generate 3 improved variations of prompt #2.\n'})}),"\n",(0,i.jsx)(n.h3,{id:"meta-prompt-for-ape",children:"Meta-Prompt for APE"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"You are an expert prompt engineer. Your task is to create effective prompts for [SPECIFIC TASK].\n\nRequirements:\n- The prompt should be clear and unambiguous\n- It should work well across diverse inputs\n- Include any necessary context or formatting instructions\n\nGenerate 5 candidate prompts, then explain why each might be effective.\n"})}),"\n",(0,i.jsx)(n.h2,{id:"advanced-techniques",children:"Advanced Techniques"}),"\n",(0,i.jsx)(n.h3,{id:"chain-of-thought-ape",children:"Chain-of-Thought APE"}),"\n",(0,i.jsx)(n.p,{children:"APE can be combined with chain-of-thought prompting to generate prompts that encourage step-by-step reasoning:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"Generate a prompt that asks the model to solve math word problems by thinking step by step. The prompt should encourage the model to:\n1. Identify what information is given\n2. Determine what needs to be found\n3. Set up the calculation\n4. Solve and verify the answer\n"})}),"\n",(0,i.jsx)(n.h3,{id:"multi-objective-ape",children:"Multi-Objective APE"}),"\n",(0,i.jsx)(n.p,{children:"When optimizing for multiple criteria simultaneously:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"Create prompts for summarizing research papers that optimize for:\n- Accuracy (capturing key findings)\n- Brevity (under 100 words)\n- Accessibility (understandable to non-experts)\n\nGenerate 3 prompts that balance these objectives.\n"})}),"\n",(0,i.jsx)(n.h2,{id:"evaluation-and-testing",children:"Evaluation and Testing"}),"\n",(0,i.jsx)(n.p,{children:"Effective APE requires systematic evaluation:"}),"\n",(0,i.jsx)(n.h3,{id:"quantitative-metrics",children:"Quantitative Metrics"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Accuracy"}),": Percentage of correct outputs on test cases"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Consistency"}),": Variance in outputs across multiple runs"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Efficiency"}),": Token usage and response time"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"qualitative-assessment",children:"Qualitative Assessment"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Clarity"}),": How well the prompt communicates the task"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Robustness"}),": Performance across edge cases and diverse inputs"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Generalization"}),": Effectiveness on unseen examples"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"implementation-example",children:"Implementation Example"}),"\n",(0,i.jsx)(n.p,{children:"Here's a complete APE workflow for creating a code documentation prompt:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:'Step 1: Define the task\nTask: Generate clear, concise documentation for Python functions\n\nStep 2: Provide examples\nInput: def calculate_area(radius): return 3.14159 * radius ** 2\nOutput: Calculates the area of a circle given its radius. Returns the area as a float.\n\nStep 3: Generate candidate prompts\n1. "Write documentation for this Python function:"\n2. "Create a brief description of what this function does:"\n3. "Generate a docstring explaining this function\'s purpose and return value:"\n4. "Describe this function in one clear sentence:"\n5. "Document this function including its purpose and output:"\n\nStep 4: Test and evaluate\n[Test each prompt on validation set]\n\nStep 5: Select and refine best performer\nBest: Prompt #3\nRefined: "Generate a concise docstring for this Python function, explaining its purpose, parameters, and return value:"\n'})}),"\n",(0,i.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsx)(n.h3,{id:"for-prompt-generation",children:"For Prompt Generation"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Provide diverse, high-quality examples"}),"\n",(0,i.jsx)(n.li,{children:"Be specific about desired output format and style"}),"\n",(0,i.jsx)(n.li,{children:"Include edge cases in your evaluation set"}),"\n",(0,i.jsx)(n.li,{children:"Consider the target model's capabilities and limitations"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"for-evaluation",children:"For Evaluation"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Use held-out test sets to avoid overfitting"}),"\n",(0,i.jsx)(n.li,{children:"Evaluate on multiple metrics relevant to your use case"}),"\n",(0,i.jsx)(n.li,{children:"Test prompts with different model temperatures and sampling methods"}),"\n",(0,i.jsx)(n.li,{children:"Consider human evaluation for subjective tasks"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"for-iteration",children:"For Iteration"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Start with simple prompts and gradually increase complexity"}),"\n",(0,i.jsx)(n.li,{children:"Document what works and what doesn't for future reference"}),"\n",(0,i.jsx)(n.li,{children:"Consider prompt ensembles for critical applications"}),"\n",(0,i.jsx)(n.li,{children:"Regular re-evaluation as models and tasks evolve"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"limitations-and-considerations",children:"Limitations and Considerations"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Computational Cost"}),": APE requires multiple model calls for generation and evaluation, which can be expensive."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Evaluation Challenges"}),": Defining good evaluation metrics can be difficult for subjective or creative tasks."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Overfitting Risk"}),": Prompts optimized on small datasets may not generalize well."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Context Dependence"}),": Optimal prompts may vary significantly across different models or domains."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Human Oversight"}),": Automated prompt generation should be combined with human review, especially for sensitive applications."]}),"\n",(0,i.jsx)(n.h2,{id:"integration-with-other-techniques",children:"Integration with Other Techniques"}),"\n",(0,i.jsx)(n.p,{children:"APE can be combined with other prompting techniques:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Few-shot learning"}),": Generate prompts that include optimal examples"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Chain-of-thought"}),": Create prompts that encourage reasoning"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Self-consistency"}),": Develop prompts optimized for multiple sampling"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Zhou, Y., et al. (2022). Large Language Models Are Human-Level Prompt Engineers. arXiv preprint arXiv:2211.01910"}),"\n",(0,i.jsx)(n.li,{children:"Reynolds, L., & McDonell, K. (2021). Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm. Extended Abstracts of CHI 2021"}),"\n",(0,i.jsx)(n.li,{children:"Wei, J., et al. (2022). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. NeurIPS 2022"}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},9782:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/APE-99afd58c2af49af55ace57959e685ae6.png"},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var i=t(6540);const s={},r=i.createContext(s);function a(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);